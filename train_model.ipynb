{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24fd85b-76ad-4657-b160-5fc0ce0d0e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Алевтина\\Desktop\\jupyter\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import torch\n",
    "import torch.nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.base\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import evaluate\n",
    "import seqeval\n",
    "import csv\n",
    "from seqeval.metrics import f1_score\n",
    "from transformers import   AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db8805dc-2dd5-4624-8e74-215803a1f43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>[(0, 2, 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aala</td>\n",
       "      <td>[(0, 4, 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aarcca</td>\n",
       "      <td>[(0, 6, 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abon</td>\n",
       "      <td>[(0, 4, 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abso</td>\n",
       "      <td>[(0, 4, 'B-BRAND')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample           annotation\n",
       "0      aa        [(0, 2, 'O')]\n",
       "1    aala        [(0, 4, 'O')]\n",
       "2  aarcca        [(0, 6, 'O')]\n",
       "3    abon        [(0, 4, 'O')]\n",
       "4    abso  [(0, 4, 'B-BRAND')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\",delimiter=';')\n",
    "extended_percent_samples = pd.read_csv(\"Extended_Percent_samples.csv\",delimiter=';')\n",
    "extended_volume_samples = pd.read_csv(\"Extended_Volume_samples.csv\",delimiter=';')\n",
    "extended_percent_samples2 = pd.read_csv(\"percent.csv\",delimiter=';')\n",
    "extended_volume_samples2 = pd.read_csv(\"volume.csv\",delimiter=';')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdd90c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label2id = {}\n",
    "for index in data.index:\n",
    "    row = data.loc[index]\n",
    "    for label_tuple in ast.literal_eval(row['annotation']):\n",
    "     label = label_tuple[2]   \n",
    "     if label  == '0' :\n",
    "           label  = 'O' \n",
    "     \n",
    "     label2id.setdefault( label ,len(label2id))\n",
    "id2label = {value: key for key, value in label2id.items()}     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92669cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-BRAND',\n",
       " 2: 'B-TYPE',\n",
       " 3: 'I-BRAND',\n",
       " 4: 'I-TYPE',\n",
       " 5: 'B-PERCENT',\n",
       " 6: 'B-VOLUME',\n",
       " 7: 'I-VOLUME',\n",
       " 8: 'I-PERCENT'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a5650d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_priority = {'O' : 0, 'B-TYPE' : 1, 'B-BRAND' : 2, 'B-VOLUME' : 3 , 'B-PERCENT' : 4}\n",
    "def PrepareData(data):\n",
    " rows_list = []\n",
    " for index in data.index:\n",
    "    row = data.loc[index]\n",
    "    labels = []\n",
    "    labels_id = []\n",
    "    original_tuple = []\n",
    "    for label_tuple in ast.literal_eval(row['annotation']):\n",
    "       label = label_tuple[2]   \n",
    "       if label  == '0' :\n",
    "           label  = 'O'\n",
    "\n",
    "       labels_id.append(label2id[label])\n",
    "       labels.append(label) \n",
    "       original_tuple.append(label_tuple)\n",
    "    \n",
    "    \n",
    "    class_for_split = max(class_priority.get(label,-1) for label in labels)\n",
    "    dict1 = {'words' : row['sample'].split(' '), 'labels_id' : labels_id, 'labels' :  labels ,'labels_string' : \" \".join(str(item) for item in set(labels)),'classes_for_split' : class_for_split ,  'original_tuple' : original_tuple , 'sample' : row['sample'], 'annotation' : row['annotation'] }\n",
    "    rows_list.append(dict1)\n",
    " return  pd.DataFrame(rows_list)    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e34864db",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df = PrepareData(data)\n",
    "extended_percent_df = PrepareData(extended_percent_samples)\n",
    "extended_volume_df = PrepareData(extended_volume_samples)\n",
    "extended_percent_df2 = PrepareData(extended_percent_samples2)\n",
    "extended_volume_df2 = PrepareData(extended_volume_samples2)\n",
    "data_exclusively_for_validation = prepared_df[prepared_df['classes_for_split'] > 2]\n",
    "other_data = prepared_df[prepared_df['classes_for_split'] <= 2]\n",
    "\n",
    "\n",
    "train,val  =  train_test_split(other_data,test_size=0.1,shuffle=True,stratify=other_data['classes_for_split'])\n",
    "\n",
    " \n",
    "\n",
    "val = pd.concat([val,data_exclusively_for_validation]).drop(['labels','original_tuple','labels_string' , 'classes_for_split'],axis=1)\n",
    "train = pd.concat([train,extended_percent_df, extended_percent_df, extended_percent_df, extended_volume_df, extended_volume_df, extended_volume_df, extended_percent_df2, extended_volume_df2]).drop(['labels','original_tuple','labels_string' , 'classes_for_split'],axis=1)\n",
    "val_dataset = Dataset.from_pandas(val,preserve_index=False)\n",
    "train_dataset =  Dataset.from_pandas(train,preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fae204b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classes_for_split\n",
       "1    0.705846\n",
       "2    0.264100\n",
       "0    0.027008\n",
       "3    0.002092\n",
       "4    0.000954\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_df.groupby('classes_for_split').count()['labels'].nlargest(25) / prepared_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63172396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels_string\n",
       "B-TYPE                             0.483652\n",
       "B-TYPE B-BRAND                     0.172324\n",
       "I-TYPE B-TYPE                      0.144398\n",
       "B-TYPE O                           0.069208\n",
       "B-BRAND                            0.065649\n",
       "O                                  0.027008\n",
       "B-TYPE I-BRAND B-BRAND             0.011743\n",
       "I-TYPE B-TYPE O                    0.008477\n",
       "O B-BRAND                          0.004477\n",
       "I-TYPE B-TYPE B-BRAND              0.004404\n",
       "I-BRAND B-BRAND                    0.003046\n",
       "B-TYPE O B-BRAND                   0.000844\n",
       "I-VOLUME B-TYPE B-VOLUME           0.000734\n",
       "I-TYPE B-TYPE I-BRAND B-BRAND      0.000697\n",
       "I-BRAND O B-BRAND                  0.000661\n",
       "B-PERCENT B-TYPE                   0.000550\n",
       "I-TYPE B-TYPE B-VOLUME             0.000367\n",
       "B-TYPE O B-VOLUME                  0.000294\n",
       "B-PERCENT I-TYPE B-TYPE            0.000183\n",
       "B-PERCENT B-TYPE I-PERCENT         0.000147\n",
       "B-TYPE B-VOLUME                    0.000147\n",
       "I-VOLUME I-TYPE B-TYPE B-VOLUME    0.000147\n",
       "B-TYPE B-VOLUME B-BRAND            0.000110\n",
       "B-TYPE I-BRAND                     0.000110\n",
       "B-TYPE I-BRAND O B-BRAND           0.000110\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg = prepared_df.groupby('labels_string').count()['labels'].nlargest(25)\n",
    "\n",
    "df_agg / prepared_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ace4529",
   "metadata": {},
   "source": [
    "Finetune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fd50598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'FacebookAI/xlm-roberta-large'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name, num_labels=len(id2label), id2label=id2label, label2id=label2id\n",
    ")\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b2686ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"words\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"labels_id\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9df5f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2800/2800 [00:00<00:00, 27458.11 examples/s]\n",
      "Map: 100%|██████████| 24822/24822 [00:01<00:00, 23696.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_val_dataset = val_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7332a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "def get_results(eval_predictions, predictions):\n",
    "  \n",
    "  \n",
    "  true_predictions = [\n",
    "        [id2label[p.item()] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, eval_predictions.label_ids)\n",
    "    ]\n",
    "\n",
    "  true_labels = [\n",
    "        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions,  eval_predictions.label_ids)\n",
    "    ]\n",
    "  \n",
    "  f1 = f1_score(true_predictions, true_labels, average='macro')\n",
    "  results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "  \n",
    "  return {\"f1\": f1, \"results\": results}\n",
    "\n",
    "\n",
    "def compute_metrics(eval_predictions):\n",
    "   softmax = torch.nn.Softmax(dim=2)\n",
    "   softmax_predictions = softmax(torch.tensor(eval_predictions.predictions))\n",
    "   \n",
    "   predictions = np.argmax(softmax_predictions, axis=2)\n",
    "   \n",
    "   predictions_modified_zero_threshold = []\n",
    "   for scores in softmax_predictions:\n",
    "     predictions_modified_zero_threshold_batch = []\n",
    "     for scores_row in scores:\n",
    "       prediction = 0\n",
    "       if scores_row[0] < 0.1:\n",
    "         prediction = np.argmax(scores_row)\n",
    "       predictions_modified_zero_threshold_batch.append(prediction)\n",
    "     predictions_modified_zero_threshold.append(predictions_modified_zero_threshold_batch)\n",
    "      \n",
    "   predictions_modified_zero_threshold = torch.tensor(predictions_modified_zero_threshold)\n",
    "   argmax_results = get_results(eval_predictions, predictions)\n",
    "   f1_modified_zero_threshold = get_results(eval_predictions, predictions_modified_zero_threshold)\n",
    " \n",
    "\n",
    "   metrics = {\n",
    "        \"precision\": argmax_results[\"results\"][\"overall_precision\"],\n",
    "        \"recall\": argmax_results[\"results\"][\"overall_recall\"],\n",
    "        \"accuracy\": argmax_results[\"results\"][\"overall_accuracy\"],\n",
    "        \"f1 argmax\": argmax_results[\"f1\"],\n",
    "        \"f1 predictions modified zero threshold\": f1_modified_zero_threshold[\"f1\"],\n",
    "        \"f1 brand\": argmax_results[\"results\"][\"BRAND\"]['f1'],\n",
    "        \"f1 type\": argmax_results[\"results\"][\"TYPE\"]['f1'],\n",
    "        \"f1 percent\": argmax_results[\"results\"][\"PERCENT\"]['f1'],\n",
    "        \"f1 volume\": argmax_results[\"results\"][\"VOLUME\"]['f1'],\n",
    "        \"brand support\": np.float64(argmax_results[\"results\"][\"BRAND\"]['number']),\n",
    "        \"type support\": np.float64(argmax_results[\"results\"][\"TYPE\"]['number']),\n",
    "        \"percent support\": np.float64(argmax_results[\"results\"][\"PERCENT\"]['number']),\n",
    "        \"volume support\": np.float64(argmax_results[\"results\"][\"VOLUME\"]['number']),\n",
    "    }\n",
    "   \n",
    "   return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1320176b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='2160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  23/2160 00:17 < 29:11, 1.22 it/s, Epoch 0.10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     14\u001b[39m train_ds = concatenate_datasets([tokenized_train_dataset, tokenized_val_dataset])\n\u001b[32m     16\u001b[39m trainer = Trainer(\n\u001b[32m     17\u001b[39m     model=model,\n\u001b[32m     18\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     compute_metrics=compute_metrics,\n\u001b[32m     23\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m trainer.save_model()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Алевтина\\Desktop\\jupyter\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Алевтина\\Desktop\\jupyter\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2565\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2559\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m   2560\u001b[39m     tr_loss_step = \u001b[38;5;28mself\u001b[39m.training_step(model, inputs, num_items_in_batch)\n\u001b[32m   2562\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2563\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2564\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2566\u001b[39m ):\n\u001b[32m   2567\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2568\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n\u001b[32m   2569\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models/FacebookAI/xml-roberta-large\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"no\",\n",
    "    save_strategy=\"no\",\n",
    "    load_best_model_at_end=False,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "train_ds = concatenate_datasets([tokenized_train_dataset, tokenized_val_dataset])\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
